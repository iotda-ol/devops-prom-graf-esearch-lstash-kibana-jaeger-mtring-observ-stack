# Prometheus Alert Rules
# Production-ready alert definitions for application monitoring

groups:
  # ============================================================================
  # APPLICATION ALERTS
  # ============================================================================
  - name: application
    interval: 30s
    rules:
      # High HTTP error rate (5xx errors)
      - alert: HighHTTPErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service, job)
            /
            sum(rate(http_requests_total[5m])) by (service, job)
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          team: application
        annotations:
          summary: "High HTTP error rate on {{ $labels.service }}"
          description: "Service {{ $labels.service }} has a {{ $value |humanizePercentage }} error rate (threshold: 5%)"
          runbook_url: "https://runbook.example.com/HighHTTPErrorRate"
      
      # High HTTP 4xx rate (client errors)
      - alert: High4xxRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"4.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.20
        for: 10m
        labels:
          severity: warning
          team: application
        annotations:
          summary: "High 4xx error rate on {{ $labels.service }}"
          description: "Service {{ $labels.service }} has a {{ $value | humanizePercentage }} 4xx rate"
      
      # High latency (p95 > 1s)
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 1
        for: 10m
        labels:
          severity: warning
          team: application
        annotations:
          summary: "High latency on {{ $labels.service }}"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.service }}"
          runbook_url: "https://runbook.example.com/HighLatency"
      
      # Very high latency (p95 > 3s)
      - alert: VeryHighLatency
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 3
        for: 5m
        labels:
          severity: critical
          team: application
        annotations:
          summary: "Very high latency on {{ $labels.service }}"
          description: "95th percentile latency is {{ $value }}s for {{ $labels.service }}"
      
      # Service down
      - alert: ServiceDown
        expr: up{job="app-metrics"} == 0
        for: 2m
        labels:
          severity: critical
          team: application
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: "{{ $labels.job }}/{{ $labels.instance }} has been down for more than 2 minutes"
          runbook_url: "https://runbook.example.com/ServiceDown"
      
      # High request rate (potential DDoS)
      - alert: HighRequestRate
        expr: |
          sum(rate(http_requests_total[1m])) by (service) > 10000
        for: 5m
        labels:
          severity: warning
          team: application
        annotations:
          summary: "Unusually high request rate on {{ $labels.service }}"
          description: "{{ $labels.service }} is receiving {{ $value }} requests/second"
      
      # Low throughput (possible issue)
      - alert: LowThroughput
        expr: |
          sum(rate(http_requests_total[5m])) by (service) < 1
        for: 15m
        labels:
          severity: warning
          team: application
        annotations:
          summary: "Low request throughput on {{ $labels.service }}"
          description: "{{ $labels.service }} is only receiving {{ $value }} requests/second"

  # ============================================================================
  # INFRASTRUCTURE ALERTS
  # ============================================================================
  - name: infrastructure
    interval: 30s
    rules:
      # High CPU usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 15m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | humanize }}% on {{ $labels.instance }}"
          runbook_url: "https://runbook.example.com/HighCPUUsage"
      
      # Critical CPU usage
      - alert: CriticalCPUUsage
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Critical CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | humanize }}% on {{ $labels.instance }}"
      
      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanize }}% on {{ $labels.instance }}"
          runbook_url: "https://runbook.example.com/HighMemoryUsage"
      
      # Critical memory usage
      - alert: CriticalMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Critical memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanize }}% on {{ $labels.instance }}"
      
      # Low disk space
      - alert: LowDiskSpace
        expr: |
          (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs"} / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.lxcfs"}) * 100 < 15
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk {{ $labels.mountpoint }} on {{ $labels.instance }} has only {{ $value | humanize }}% free space"
          runbook_url: "https://runbook.example.com/LowDiskSpace"
      
      # Critical disk space
      - alert: CriticalDiskSpace
        expr: |
          (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs"} / node_filesystem_size_bytes{fstype!~"tmpfs|fuse.lxcfs"}) * 100 < 5
        for: 2m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Critical disk space on {{ $labels.instance }}"
          description: "Disk {{ $labels.mountpoint }} on {{ $labels.instance }} has only {{ $value | humanize }}% free space"
      
      # High disk I/O
      - alert: HighDiskIO
        expr: |
          rate(node_disk_io_time_seconds_total[5m]) > 0.9
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High disk I/O on {{ $labels.instance }}"
          description: "Disk {{ $labels.device }} on {{ $labels.instance }} has high I/O utilization"
      
      # Instance down
      - alert: InstanceDown
        expr: up == 0
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Instance {{ $labels.instance }} is down"
          description: "{{ $labels.job }}/{{ $labels.instance }} has been down for more than 5 minutes"
          runbook_url: "https://runbook.example.com/InstanceDown"
      
      # High network traffic
      - alert: HighNetworkTraffic
        expr: |
          rate(node_network_receive_bytes_total[5m]) > 100000000
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High network receive traffic on {{ $labels.instance }}"
          description: "Interface {{ $labels.device }} on {{ $labels.instance }} is receiving {{ $value | humanize }}B/s"

  # ============================================================================
  # DATABASE ALERTS  
  # ============================================================================
  - name: database
    interval: 30s
    rules:
      # PostgreSQL down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 2m
        labels:
          severity: critical
          team: database
          service: database
        annotations:
          summary: "PostgreSQL instance is down"
          description: "PostgreSQL instance {{ $labels.instance }} is down"
          runbook_url: "https://runbook.example.com/PostgreSQLDown"
      
      # Too many connections
      - alert: PostgreSQLTooManyConnections
        expr: |
          sum by (instance) (pg_stat_activity_count) / sum by (instance) (pg_settings_max_connections) > 0.8
        for: 5m
        labels:
          severity: warning
          team: database
          service: database
        annotations:
          summary: "PostgreSQL has too many connections"
          description: "PostgreSQL instance {{ $labels.instance }} is using {{ $value | humanizePercentage }} of available connections"
      
      # Slow queries
      - alert: PostgreSQLSlowQueries
        expr: |
          rate(pg_stat_activity_max_tx_duration[5m]) > 300
        for: 10m
        labels:
          severity: warning
          team: database
          service: database
        annotations:
          summary: "PostgreSQL has slow queries"
          description: "PostgreSQL instance {{ $labels.instance }} has queries running for more than 5 minutes"
      
      # Replication lag
      - alert: PostgreSQLReplicationLag
        expr: |
          pg_replication_lag > 30
        for: 5m
        labels:
          severity: critical
          team: database
          service: database
        annotations:
          summary: "PostgreSQL replication lag is high"
          description: "Replication lag is {{ $value }}seconds on {{ $labels.instance }}"

  # ============================================================================
  # KUBERNETES ALERTS
  # ============================================================================
  - name: kubernetes
    interval: 30s
    rules:
      # Pod crash looping
      - alert: PodCrashLooping
        expr: |
          rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has restarted {{ $value }} times in the last 15 minutes"
      
      # Pod not ready
      - alert: PodNotReady
        expr: |
          kube_pod_status_phase{phase!~"Running|Succeeded"} > 0
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in {{ $labels.phase }} state for over 10 minutes"
      
      # Deployment replica mismatch
      - alert: DeploymentReplicasMismatch
        expr: |
          kube_deployment_spec_replicas != kube_deployment_status_replicas_available
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} replica mismatch"
          description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $value }} unavailable replicas"
      
      # Node not ready
      - alert: NodeNotReady
        expr: |
          kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Node {{ $labels.node }} is not ready"
          description: "Node {{ $labels.node }} has been in NotReady state for over 5 minutes"
      
      # High pod memory usage
      - alert: PodHighMemory
        expr: |
          sum(container_memory_usage_bytes{pod!=""}) by (pod, namespace) / sum(container_spec_memory_limit_bytes{pod!=""}) by (pod, namespace) > 0.9
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} memory usage is high"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is using {{ $value | humanizePercentage }} of memory limit"
